freqs = sapply(splitNames, function(x) x[2]),
region = sapply(splitNames, function(x) x[3])
)
long_df <- expand.grid(Row_Region = freq_region_df$region,
Col_Region = freq_region_df$region)
long_df$Correlation <- as.vector(cor_matrix)
reg_df = long_df %>% group_by(Row_Region, Col_Region) %>%
summarize(corVal = mean(Correlation))
reg_df = reg_df %>%
pivot_wider(names_from = Col_Region, values_from = corVal) %>%
ungroup() %>%  # Ungroup to avoid automatic inclusion
select(-Row_Region)  # Remove Row_Region
rownames(reg_df) = colnames(reg_df)
reg_df = as.matrix(reg_df)
corrplot(reg_df, method = "color",
type = "lower", tl.cex = 0.8,
col.lim = c(min(reg_df), max(reg_df)), is.corr = F)
# Chunk 1
# Set rendering parameters
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
gitHubPath = 'C:/Users/Adam/Documents/GitHub/MasterStatsUsingR/'
library(tidyverse) # data manipulation and visualization
source(paste0(gitHubPath, 'courseTheme.R'))
# Load package
library(corrplot)
# Chunk 2: EEG
#Key variable name: pow_delta_O
df = read.csv(paste0(gitHubPath, '\\data\\restingEEG.csv'))
df$dummy = as.factor(1)
df <- df %>% filter(pow_delta_O < 250, pow_delta_O > 0)
# Chunk 3: cor mat
# Compute correlation matrix
cor_matrix <- cor(select(df, colnames(df)[grepl("pow", colnames(df))]))
corrplot(cor_matrix, method = "color", type = "lower", tl.cex = 0.8)
# Chunk 4: region mat
splitNames = str_split(rownames(cor_matrix), "_")
freq_region_df <- data.frame(
variable = rownames(cor_matrix),
freqs = sapply(splitNames, function(x) x[2]),
region = sapply(splitNames, function(x) x[3])
)
long_df <- expand.grid(Row_Region = freq_region_df$region,
Col_Region = freq_region_df$region)
long_df$Correlation <- as.vector(cor_matrix)
reg_df = long_df %>% group_by(Row_Region, Col_Region) %>%
summarize(corVal = mean(Correlation))
reg_df = reg_df %>%
pivot_wider(names_from = Col_Region, values_from = corVal) %>%
ungroup() %>%  # Ungroup to avoid automatic inclusion
select(-Row_Region)  # Remove Row_Region
rownames(reg_df) = colnames(reg_df)
reg_df = as.matrix(reg_df)
minVal = max(reg_df)
maxVal = max(reg_df)
corrplot(reg_df, method = "color",
type = "lower", tl.cex = 0.8,
col.lim = c(minVal, maxVal), is.corr = F)
corrplot(reg_df, method = "color",
type = "lower", tl.cex = 0.8,
col.lim = c(minVal, maxVal), is.corr = F)
max(reg_df)
max(reg_df)
minVal = min(reg_df)
maxVal = max(reg_df)
corrplot(reg_df, method = "color",
type = "lower", tl.cex = 0.8,
col.lim = c(minVal, maxVal), is.corr = F)
long_df <- expand.grid(Row_Freq = freq_region_df$freqs,
Col_Freq = freq_region_df$freqs)
long_df$Correlation <- as.vector(cor_matrix)
freq_df = long_df %>% group_by(Row_Freq, Col_Freq) %>%
summarize(corVal = mean(Correlation))
freq_df = freq_df %>%
pivot_wider(names_from = Col_Freq, values_from = corVal) %>%
ungroup() %>%  # Ungroup to avoid automatic inclusion
select(-Row_Freq)  # Remove Row_Region
rownames(freq_df) = colnames(freq_df)
freq_df = as.matrix(freq_df)
corrplot(freq_df, method = "color",
type = "lower", tl.cex = 0.8,
col.lim = c(minVal, maxVal), is.corr = F)
# Compute correlation matrix
cor_matrix <- cor(select(df, colnames(df)[grepl("pow", colnames(df))]),
method = 'spearman')
corrplot(cor_matrix, method = "color", type = "lower", tl.cex = 0.8)
splitNames = str_split(rownames(cor_matrix), "_")
freq_region_df <- data.frame(
variable = rownames(cor_matrix),
freqs = sapply(splitNames, function(x) x[2]),
region = sapply(splitNames, function(x) x[3])
)
long_df <- expand.grid(Row_Region = freq_region_df$region,
Col_Region = freq_region_df$region)
long_df$Correlation <- as.vector(cor_matrix)
reg_df = long_df %>% group_by(Row_Region, Col_Region) %>%
summarize(corVal = mean(Correlation))
reg_df = reg_df %>%
pivot_wider(names_from = Col_Region, values_from = corVal) %>%
ungroup() %>%  # Ungroup to avoid automatic inclusion
select(-Row_Region)  # Remove Row_Region
rownames(reg_df) = colnames(reg_df)
reg_df = as.matrix(reg_df)
minVal = min(reg_df)
maxVal = max(reg_df)
corrplot(reg_df, method = "color",
type = "lower", tl.cex = 0.8,
col.lim = c(minVal, maxVal), is.corr = F)
long_df <- expand.grid(Row_Freq = freq_region_df$freqs,
Col_Freq = freq_region_df$freqs)
long_df$Correlation <- as.vector(cor_matrix)
freq_df = long_df %>% group_by(Row_Freq, Col_Freq) %>%
summarize(corVal = mean(Correlation))
freq_df = freq_df %>%
pivot_wider(names_from = Col_Freq, values_from = corVal) %>%
ungroup() %>%  # Ungroup to avoid automatic inclusion
select(-Row_Freq)  # Remove Row_Region
rownames(freq_df) = colnames(freq_df)
freq_df = as.matrix(freq_df)
corrplot(freq_df, method = "color",
type = "lower", tl.cex = 0.8,
col.lim = c(minVal, maxVal), is.corr = F)
minVal = min(freq_df)
maxVal = max(freq_df)
corrplot(freq_df, method = "color",
type = "lower", tl.cex = 0.8,
col.lim = c(minVal, maxVal), is.corr = F)
# Set rendering parameters
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
gitHubPath = 'C:/Users/Adam/Documents/GitHub/MasterStatsUsingR/'
library(tidyverse) # data manipulation and visualization
source(paste0(gitHubPath, 'courseTheme.R'))
library(pracma)
library(readxl)
install.packages("lares")
library(lares)
function_analysis <- files_functions(gitHubPath)
r_files <- list.files("path/to/MasterStatsUsingR", pattern = "\\.R$", recursive = TRUE, full.names = TRUE)
r_files <- list.files(gitHubPath, pattern = "\\.R$", recursive = TRUE, full.names = TRUE)
r_files
r_files <- list.files(gitHubPath, pattern = "\\.RMD$", recursive = TRUE, full.names = TRUE)
r_files <- list.files(gitHubPath, pattern = "\\.Rmd", recursive = TRUE, full.names = TRUE)
r_files
for (file in r_files) {
tryCatch({
parse(file)
cat("Parsed successfully:", file, "\n")
}, error = function(e) {
cat("Error in:", file, "\n", e$message, "\n")
})
}
r_files <- list.files(gitHubPath, pattern = "\\.Rmd$", recursive = TRUE, full.names = TRUE)
# Initialize vectors for good and bad files
good_files <- c()
bad_files <- c()
# Identify good and bad files
for (file in r_files) {
tryCatch({
parse(file)  # Try parsing the file
good_files <- c(good_files, file)  # If successful, add to good list
}, error = function(e) {
bad_files <- c(bad_files, file)  # If error, add to bad list
})
}
# Print summary of good and bad files
cat("✅ Good files:", length(good_files), "\n")
cat("❌ Bad files:", length(bad_files), "\n")
# Identify good and bad files
for (file in r_files) {
tryCatch({
parse(file)  # Try parsing the file
good_files <- c(good_files, file)  # If successful, add to good list
}, error = function(e) {
bad_files <- c(bad_files, file)  # If error, add to bad list
})
}
file = r_files[10]
file
parse(file)
bad_files <- c(bad_files, file)  # If error, add to bad list
# Identify good and bad files
for (file in r_files) {
tryCatch({
parse(file)  # Try parsing the file
good_files <- c(good_files, file)  # If successful, add to good list
}, error = function(e) {
bad_files <- c(bad_files, file)  # If error, add to bad list
})
}
# Identify good and bad files
for (file in r_files) {
tryCatch({
# Read the file first, then parse the content
code <- readLines(file, warn = FALSE)
parse(text = code)  # Parse the actual content
good_files <- c(good_files, file)  # If successful, add to good list
}, error = function(e) {
bad_files <- c(bad_files, file)  # If error, add to bad list
})
}
# Read the file first, then parse the content
code <- readLines(file, warn = FALSE)
parse(text = code)  # Parse the actual content
# Initialize vectors for good and bad files
good_files <- c()
bad_files <- c()
# Identify good and bad files
for (file in r_files) {
tryCatch({
# Read the file first, then parse the content
code <- readLines(file, warn = FALSE)
parse(text = code)  # Parse the actual content
good_files <<- c(good_files, file)  # If successful, add to good list
}, error = function(e) {
bad_files <<- c(bad_files, file)  # If error, add to bad list
})
}
function_list <- lapply(r_files, function(file) {
tryCatch({
list.functions.in.file(file)
}, error = function(e) {
message(paste("Error in file:", file, "\n", e))
NULL
})
})
install.packages("NCmisc")
library("NCmisc")
function_list <- lapply(r_files, function(file) {
tryCatch({
list.functions.in.file(file)
}, error = function(e) {
message(paste("Error in file:", file, "\n", e))
NULL
})
})
View(function_list)
library(stringr)
library(NCmisc)
library(purrr)
# List all R Markdown files
rmd_files <- list.files(gitHubPath, pattern = "\\.Rmd$", recursive = TRUE, full.names = TRUE)
# Function to extract and analyze functions from R code chunks in .Rmd files
extract_functions_from_rmd <- function(file) {
tryCatch({
# Read the file content
lines <- readLines(file, warn = FALSE)
# Identify lines that are inside R code chunks (between ```{r} and ```)
r_code_lines <- c()
in_chunk <- FALSE
for (line in lines) {
if (str_detect(line, "^```\\{r")) {
in_chunk <- TRUE  # Start of R chunk
} else if (str_detect(line, "^```")) {
in_chunk <- FALSE  # End of R chunk
} else if (in_chunk) {
r_code_lines <- c(r_code_lines, line)  # Collect R lines
}
}
# Parse extracted R code
if (length(r_code_lines) == 0) return(NULL)  # Skip if no R code found
parsed_code <- parse(text = r_code_lines)
# Extract functions from parsed code
funcs <- list.functions.in.file(textConnection(r_code_lines))
# Return results as a data frame
data.frame(
File = file,
Function = names(funcs),
Package = unlist(funcs),
stringsAsFactors = FALSE
)
}, error = function(e) {
message(paste("Error processing file:", file, "\n", e$message))
NULL
})
}
# Apply function to all .Rmd files
function_analysis <- map_dfr(rmd_files, extract_functions_from_rmd)
# Print extracted functions
print(function_analysis)
View(function_list)
# List all R Markdown files
rmd_files <- list.files(gitHubPath, pattern = "\\.Rmd$", recursive = TRUE, full.names = TRUE)
# Function to extract and analyze functions from R code chunks in .Rmd files
extract_functions_from_rmd <- function(file) {
tryCatch({
# Read the file content
lines <- readLines(file, warn = FALSE)
# Identify lines that are inside R code chunks (between ```{r} and ```)
r_code_lines <- c()
in_chunk <- FALSE
for (line in lines) {
if (str_detect(line, "^```\\{r")) {
in_chunk <- TRUE  # Start of R chunk
} else if (str_detect(line, "^```")) {
in_chunk <- FALSE  # End of R chunk
} else if (in_chunk) {
r_code_lines <- c(r_code_lines, line)  # Collect R lines
}
}
# Parse extracted R code
if (length(r_code_lines) == 0) return(NULL)  # Skip if no R code found
parsed_code <- parse(text = r_code_lines)
# Extract functions from parsed code
funcs <- list.functions.in.file(textConnection(r_code_lines))
# Return results as a data frame
data.frame(
File = file,
Function = names(funcs),
Package = unlist(funcs),
stringsAsFactors = FALSE
)
}, error = function(e) {
message(paste("Error processing file:", file, "\n", e$message))
NULL
})
}
# Apply function to all .Rmd files
function_analysis <- map_dfr(rmd_files, extract_functions_from_rmd)
# Set rendering parameters
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
gitHubPath = 'C:/Users/Adam/Documents/GitHub/MasterStatsUsingR/'
library(tidyverse) # data manipulation and visualization
source(paste0(gitHubPath, 'courseTheme.R'))
library(pracma)
library(readxl)
install.packages("lares")
library(lares)
install.packages("NCmisc")
library("NCmisc")
library(stringr)
library(NCmisc)
library(purrr)
# List all R Markdown files
rmd_files <- list.files(gitHubPath, pattern = "\\.Rmd$", recursive = TRUE, full.names = TRUE)
# Function to extract and analyze functions from R code chunks in .Rmd files
extract_functions_from_rmd <- function(file) {
tryCatch({
# Read the file content
lines <- readLines(file, warn = FALSE)
# Identify lines that are inside R code chunks (between ```{r} and ```)
r_code_lines <- c()
in_chunk <- FALSE
for (line in lines) {
if (str_detect(line, "^```\\{r")) {
in_chunk <- TRUE  # Start of R chunk
} else if (str_detect(line, "^```")) {
in_chunk <- FALSE  # End of R chunk
} else if (in_chunk) {
r_code_lines <- c(r_code_lines, line)  # Collect R lines
}
}
# Parse extracted R code
if (length(r_code_lines) == 0) return(NULL)  # Skip if no R code found
parsed_code <- parse(text = r_code_lines)
# Extract functions from parsed code
funcs <- list.functions.in.file(textConnection(r_code_lines))
# Return results as a data frame
data.frame(
File = file,
Function = names(funcs),
Package = unlist(funcs),
stringsAsFactors = FALSE
)
}, error = function(e) {
message(paste("Error processing file:", file, "\n", e$message))
NULL
})
}
# Apply function to all .Rmd files
function_analysis <- map_dfr(rmd_files, extract_functions_from_rmd)
# Apply function to all .Rmd files
function_analysis <- map_dfr(rmd_files, extract_functions_from_rmd)
# Apply function to all .Rmd files
function_analysis <- map_dfr(rmd_files, extract_functions_from_rmd)
library(purrr)
# List all R Markdown files
rmd_files <- list.files(gitHubPath, pattern = "\\.Rmd$", recursive = TRUE, full.names = TRUE)
# Function to extract and analyze functions from R code chunks in .Rmd files
extract_functions_from_rmd <- function(file) {
tryCatch({
# Read the file content
lines <- readLines(file, warn = FALSE)
# Identify lines that are inside R code chunks (between ```{r} and ```)
r_code_lines <- c()
in_chunk <- FALSE
for (line in lines) {
if (str_detect(line, "^```\\{r")) {
in_chunk <- TRUE  # Start of R chunk
} else if (str_detect(line, "^```")) {
in_chunk <- FALSE  # End of R chunk
} else if (in_chunk) {
r_code_lines <- c(r_code_lines, line)  # Collect R lines
}
}
# Parse extracted R code
if (length(r_code_lines) == 0) return(NULL)  # Skip if no R code found
parsed_code <- parse(text = r_code_lines)
# Extract functions from parsed code
funcs <- list.functions.in.file(textConnection(r_code_lines))
# Return results as a data frame
data.frame(
File = file,
Function = names(funcs),
Package = unlist(funcs),
stringsAsFactors = FALSE
)
}, error = function(e) {
message(paste("Error processing file:", file, "\n", e$message))
NULL
})
}
# Apply function to all .Rmd files
function_analysis <- map_dfr(rmd_files, extract_functions_from_rmd)
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
gitHubPath = 'C:/Users/Adam/Documents/GitHub/MasterStatsUsingR/'
library(tidyverse) # data manipulation and visualization
library(pracma)
library(readxl)
install.packages("funspotr")
library(funspotr)
rmd_files <- list.files(repo_path, pattern = "\\.Rmd$", recursive = TRUE, full.names = TRUE)
rmd_files <- list.files(gitHubPath, pattern = "\\.Rmd$", recursive = TRUE, full.names = TRUE)
spot_funs(file_path = rmd_files[10])
spot_funs(file_path = rmd_files[14])
test = spot_funs(file_path = rmd_files[14])
View(test)
test = spot_funs(file_path = rmd_files[1])
rmd_files
test = spot_funs(file_path = rmd_files[80])
View(test)
test = lapply(rmd_files, spot_funs)
test = lapply(rmd_files[1:10], spot_funs)
View(test)
combined_df <- bind_rows(test)
# Count occurrences of each function
function_counts <- combined_df %>%
count(funs, name = "occurrences")
View(function_counts)
# Count occurrences of each function
function_counts <- combined_df %>% group_by(funs) %>%
summarize(n = n())
View(function_counts)
# Count occurrences of each function
function_counts <- combined_df %>% group_by(funs, pkgs) %>%
summarize(n = n())
View(function_counts)
test = lapply(rmd_files, spot_funs)
test = list()
for(ii in 1:length(rmd_files)){
tryCatch(
expr = {
cur = spot_funs(rmd_files[ii])
test = c(test, cur)
},
error = function(e) {
print(paste0('warning: ', ii))
},
warning = function(w) {
print(paste0('warning: ', ii))
},
finally = {
print(ii)
}
)
}
View(test)
test = list()
for(ii in 1:length(rmd_files)){
tryCatch(
expr = {
cur = spot_funs(rmd_files[ii])
test[[ii]] = cur
},
error = function(e) {
print(paste0('warning: ', ii))
},
warning = function(w) {
print(paste0('warning: ', ii))
},
finally = {
print(ii)
}
)
}
View(test)
combined_df <- bind_rows(test)
# Count occurrences of each function
function_counts <- combined_df %>% group_by(funs, pkgs) %>%
summarize(n = n())
View(function_counts)
test = list()
for(ii in 1:length(rmd_files)){
tryCatch(
expr = {
cur = spot_funs(rmd_files[ii])
test[[ii]] = cur
},
error = function(e) {
print(paste0('warning: ', ii))
},
warning = function(w) {
print(paste0('warning: ', ii))
},
finally = {
print(ii)
}
)
}
combined_df <- bind_rows(test)
# Count occurrences of each function
function_counts <- combined_df %>% group_by(funs, pkgs) %>%
summarize(n = n())
View(function_counts)
